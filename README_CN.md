# Data_Mining_Project

## 1. 数据集描述
> 该数据集模拟了不同城市应对气候相关灾害（例如飓风、龙卷风、热浪、野火和洪水）的响应情况。每一行代表一次模拟事件，包含灾害信息、城市规划方法以及结果，例如响应时间、恢复时间和损失成本。
它旨在支持以下领域的机器学习研究和应用：城市韧性建模、风险评估与缓解、气候适应规划、智慧城市设计以及灾害响应预测
该数据集根据五种不同的城市规划类型进行建模，包含来自美国十个主要城市的 500 个条目和五种灾害类型。

| 字段                      | 解释     | 说明                        |
|-------------------------|--------|---------------------------|
| **City**                | 城市名称   | 灾害发生的城市名称。                |
| **Disaster_Type**       | 灾害类型   | 如洪水、野火、热浪、飓风、龙卷风等。        |
| **Urban_Planning_Type** | 城市规划类型 | 城市采用的基础设施类型或规划策略。         |
| **Disaster_Severity**   | 灾害严重度  | 1（轻微）到 10（极端严重）的评分。       |
| **Population_Density**  | 人口密度   | 城市中每平方公里的居民人数。            |
| **Avg_Income**          | 平均收入   | 城市居民的年度平均收入（单位：USD）。      |
| **Response_Time_hr**    | 应急响应时间 | 应急服务到达现场所需的时间（小时）。        |
| **Damage_Cost_USD**     | 灾害损失成本 | 灾害造成的经济损失估算值（美元）。         |
| **Recovery_Time_days**  | 恢复时间   | 城市从灾害中恢复所需的时间（天）。         |


### 一、数据整体分析与核心问题拆解
1. **数据规模与类型**：500条样本，10个字段（3个字符串类型分类变量+6个数值变量，目标变量为连续型的`Recovery_Time_days`），属于小样本回归任务。  
2. **核心挑战**：  
   - 字符串类型变量（`City`/`Disaster_Type`/`Urban_Planning_Type`）需转化为模型可识别的特征，同时需分析其与数值变量、目标变量的关联性；  
   - 样本量较小（500条），需避免特征维度爆炸导致的过拟合，同时通过特征工程挖掘潜在信息。  


### 二、字符串类型变量处理与关联性分析
#### 1. 分类变量编码策略（针对小样本的优化方案）
| 变量               | 类别数量 | 推荐编码方式       | 优势                                                                 |
|--------------------|----------|--------------------|----------------------------------------------------------------------|
| `City`             | 10       | 目标编码（Target Encoding） | 用目标变量（恢复时间）的均值/中位数编码类别，不增加维度，适合小样本   |
| `Disaster_Type`    | 5        | 目标编码/有序编码（若有逻辑） | 灾害类型无天然顺序，目标编码更优（如“洪水”对应平均恢复时间）         |
| `Urban_Planning_Type` | 5      | 目标编码           | 规划类型对恢复时间的影响可通过目标变量统计量直接量化                 |

**编码细节**：  
- 目标编码需加平滑处理（避免类别样本量极少时的极端值），公式：`编码值 = (n_i * mean_i + m * global_mean) / (n_i + m)`，其中`n_i`为类别样本量，`m`为平滑参数（建议取5-10）；  
- 对比方案：对`Disaster_Type`和`Urban_Planning_Type`可尝试独热编码（生成10个哑变量），但需配合特征选择避免维度灾难。


#### 2. 分类变量与其他变量的关联性分析
##### （1）分类变量 vs 目标变量（`Recovery_Time_days`）
- **可视化**：绘制箱线图（如不同`Disaster_Type`下的恢复时间分布），直观观察类别间差异；  
- **统计检验**：用单因素方差分析（ANOVA），检验“类别是否显著影响恢复时间”（原假设：类别均值无差异，p<0.05则拒绝原假设）。  

  *示例结论预期*：飓风（Hurricane）可能比热浪（Heatwave）恢复时间更长；“Green Infrastructure”规划类型可能比“Suburban Sprawl”恢复更快。

##### （2）分类变量 vs 数值变量（如`Damage_Cost_USD`）
- **可视化**：按分类变量分组，绘制数值变量的核密度图/小提琴图（如不同`City`的`Population_Density`分布）；  
- **关联性量化**：计算分组后的数值变量均值差异，用ANOVA检验差异显著性（如“纽约的灾害损失成本是否显著高于西雅图”）。  


### 三、数值特征处理与相关性分析
#### 1. 数值特征预处理
- **缺失值**：若存在缺失（假设缺失率<5%），用分组填充（如按`Disaster_Type`分组，用组内中位数填充`Response_Time_hr`），比全局填充更精准；  
- **异常值**：用IQR法则（`Q3 + 1.5*IQR`为上限）识别`Damage_Cost_USD`等变量的异常值，采用“截断”（替换为上限值）而非删除（避免小样本信息损失）；  
- **尺度调整**：对`Avg_Income`（大数值）、`Response_Time_hr`（小数值）进行标准化（Z-Score），避免梯度提升模型中数值尺度对特征重要性的误判。


#### 2. 数值特征相关性分析
- **变量间相关性**：计算皮尔逊相关系数（线性）和斯皮尔曼相关系数（非线性），绘制热力图，筛选高相关特征（如`Damage_Cost_USD`与`Recovery_Time_days`可能强相关，`Response_Time_hr`与`Recovery_Time_days`可能正相关）；  
- **与目标变量的单变量分析**：绘制散点图（如`Disaster_Severity` vs `Recovery_Time_days`），拟合趋势线判断单调性（正相关/负相关）。  


### 四、小样本优化：特征融合与采样策略
#### 1. 特征融合（核心提升方向）
针对小样本，通过特征融合压缩信息、增强代表性：  
- **分类+数值交互特征**：  
  - `Disaster_Type_Recovery_Mean * Disaster_Severity`（灾害类型平均恢复时间 × 严重度，量化“严重度在特定灾害中的影响”）；  
  - `Urban_Planning_Type_Encoding / Response_Time_hr`（规划类型编码 ÷ 响应时间，体现“规划有效性与响应速度的协同作用”）。  
- **数值变量组合特征**：  
  - `Population_Density * Damage_Cost_USD`（人口密度 × 损失成本，反映“受灾区域的综合损失压力”）；  
  - `(Avg_Income / 1e4) * (1 / Response_Time_hr)`（收入水平 ÷ 响应时间，体现“经济能力与应急效率的综合恢复潜力”）。  


#### 2. 采样策略（非必需，视模型表现而定）
- 500样本量对树模型（XGBoost/LightGBM）尚可，但可尝试**重复采样+交叉验证**（如5折交叉验证中，每折训练集通过bootstrap重采样增强鲁棒性）；  
- 不建议过采样（易引入噪声），若特征维度较高（如独热编码后），可结合**特征选择**（如用XGBoost的特征重要性筛选top20特征）。  


### 五、模型选择与实现方案
#### 1. 核心模型（满足必选+多样性）
| 模型                | 优势                                  | 调优重点（小样本防过拟合）                          |
|---------------------|---------------------------------------|---------------------------------------------------|
| XGBoost（回归）     | 处理非线性关系强，抗噪声              | `max_depth=3-5`，`learning_rate=0.01-0.1`，`subsample=0.8` |
| LightGBM（回归）    | 高效处理小样本，支持类别特征直接输入  | `num_leaves=20-31`（控制复杂度），`min_data_in_leaf=10` |
| CatBoost（回归）    | 自动处理类别特征，减少编码工作量      | `depth=3-5`，`l2_leaf_reg=10`（正则化）           |
| GradientBoosting（sklearn） | 基础梯度提升，稳定性高              | `n_estimators=100-200`，`max_depth=3`             |
| AdaBoost（回归）    | 弱分类器迭代优化，适合小样本         | `n_estimators=50-100`，`learning_rate=0.1`        |


#### 2. 模型评估与对比
- **评估指标**：回归任务核心指标为`RMSE`（均方根误差）、`MAE`（平均绝对误差）、`R²`（决定系数，越接近1越好）；  
- **验证方式**：5折交叉验证（避免小样本下的随机划分偏差），对比不同模型的交叉验证均值±标准差。  


### 六、执行流程总结
1. **数据加载与探索**：检查缺失/异常值，统计分类变量类别分布；  
2. **特征工程**：  
   - 分类变量：目标编码（主）+ 独热编码（对比）；  
   - 数值变量：清洗（缺失/异常）+ 标准化；  
   - 融合特征：构造6-8个交互/组合特征；  
3. **相关性分析**：生成热力图、箱线图、ANOVA检验结果；  
4. **建模与调优**：训练5种模型，用网格搜索调优超参数；  
5. **结果输出**：模型评估指标对比表、特征重要性（SHAP值可视化）、最优模型预测结果。  


### 7. 模型进一步调优

通过以上步骤，可充分挖掘分类变量与数值变量的关联，同时在小样本限制下通过特征融合提升模型泛化能力，最终实现对“恢复时间”的精准预测。需要我基于此流程提供具体代码框架（如特征编码、模型训练代码）吗？

